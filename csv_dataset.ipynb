{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ebab24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import xml.etree.ElementTree as etree\n",
    "import csv\n",
    "import getopt\n",
    "import sys\n",
    "import json\n",
    "import copy\n",
    "import tensorflow.keras.utils as TKU\n",
    "from random import shuffle\n",
    "from sklearn import utils\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import keras\n",
    "import keras.preprocessing.text as kpt\n",
    "import nltk\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Input, Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Dense, concatenate, Activation, Average\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import CSVLogger\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89edf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDir = 'C:\\\\Users\\\\morzm\\\\jup_txts\\\\csv'\n",
    "outputDir = 'C:\\\\Users\\\\morzm\\\\jup_txts\\\\csv\\\\output'\n",
    "modelDir = 'C:\\\\Users\\\\morzm\\\\jup_txts\\\\csv\\\\model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5051ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = \"C:\\\\Users\\\\morzm\\\\jup_txts\\\\csv\\\\en\\\\text\\\\\"\n",
    "label_path = \"C:\\\\Users\\\\morzm\\\\jup_txts\\\\csv\\\\en\\\\truth.txt\"\n",
    "label_file = open(label_path)\n",
    "model_path = os.path.join(modelDir, 'en_model.json')\n",
    "dic_path = os.path.join(modelDir, 'en_dictionary.json')\n",
    "twit_path = os.path.join(modelDir, 'twitter_en_data_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d255f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml to cvs\n",
    "\n",
    "with open(twit_path, 'w+', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['text', 'gender']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for filename in os.listdir(xml_path):\n",
    "        if not filename.endswith('.xml'): continue\n",
    "        # ----reading file name\n",
    "        find_file_name = os.path.splitext(filename)[0]\n",
    "        # print(find_file_name)\n",
    "        # finding author gender\n",
    "        label_file = open(label_path)\n",
    "        for row in label_file:\n",
    "            if find_file_name in row:\n",
    "                # print(find_file_name)\n",
    "                # print(row.split(':::')[1])\n",
    "                gender = row.split(':::')[1]\n",
    "\n",
    "        # print(gender)\n",
    "\n",
    "        # reading xml full path\n",
    "        xml_fullname = os.path.join(xml_path, filename)\n",
    "        tree = etree.parse(xml_fullname)\n",
    "        root = tree.getroot()\n",
    "        # reading xml file data\n",
    "        for i in range(len(root[0])):\n",
    "            writer.writerow({'text': str(root[0][i].text), 'gender': str(gender)})\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfadd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweak this code\n",
    "# define tokenize, stem\n",
    "\n",
    "\n",
    "my_df = pd.read_csv(twit_path)\n",
    "my_df['gender'] = my_df['gender'].map({'female\\r\\n': 0, 'male\\r\\n': 1})\n",
    "my_df['text'] = my_df['text'].apply(lambda x: \" \".join(stem(x) for x in x.split()))\n",
    "stop = stopwords.words('english')\n",
    "my_df['text'] = my_df['text'].apply(lambda x: \" \".join(x for x in x.split(\" \") if x not in stop))\n",
    "my_word_stop = ['the', 'in', 'of', 'is', 'a', 'to', 'an', 'be']\n",
    "my_df['text'] = my_df['text'].apply(lambda x: \" \".join(x for x in x.split(\" \") if x not in my_word_stop))\n",
    "my_df['text'] = my_df['text'].apply(lambda x: \" \".join(tokenize(x) for x in x.split(\" \")))\n",
    "# my_df['text'] = my_df['text'].apply(lambda x: \" \".join(x for x in text_processor.pre_process_doc(x) if x not in stop))\n",
    "freq = pd.Series(' '.join(my_df['text']).split()).value_counts()[:50]\n",
    "freq = list(freq.index)\n",
    "my_df['text'] = my_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0848712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
